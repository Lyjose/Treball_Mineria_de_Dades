3 Puntos MUY importantes al tener en cuenta ANTES de entrenar los modelos.

######### PUNTO 1 ###########
Usar TODOS set.seed(123) y cargar estos paquetes
library(smotefamily)
library(MLmetrics)

######### PUNTO 2 ###########
Para la partición interna del train en train/test, usaremos un 80% TRAIN, 20% TEST, por ejemplo:
  Index <- sample(1:nrow(data), size = nrow(data)*0.8)
  dataTrain <- data[Index, ]
  dataTest  <- data[-Index, ]

######### PUNTO 2 ###########
Al entrenar los modelos, caret no trae incorporado una metrica de F1, para entrenar todos los modelos y evaluarlos bajo la misma metrica, usaremos esta función:
# F1
  f1 <- function(data, lev = NULL, model = NULL) {
    f1_val <- MLmetrics::F1_Score(y_pred = data$pred, y_true = data$obs, positive = "Yes")
    c(F1 = f1_val)
  }

# Tb hay que cambiar la label de Exited para la función F1
dataTrain$Exited <- factor(dataTrain$Exited, levels = c(0,1), labels = c("No", "Yes"))
dataTest$Exited  <- factor(dataTest$Exited,  levels = c(0,1), labels = c("No", "Yes"))

# Hay que especificar en el control que se use f1 en summaryFunction ,también smote esta aqui en sampling
  control <- trainControl(
    method = "repeatedcv",
    number = 5,
    repeats = 5,
    classProbs = TRUE,
    summaryFunction = f1,
    sampling = "smote",
    verboseIter = TRUE
  )

Y en el modelo = train(....,trControl = control, metric = "F1", ... )

################## PUNTO 4 ####################
PARA KAGGLE
pred_test <- predict(....modelo...., newdata = data_imputed_AREG_test, type = "raw")

submission <- data.frame(
  ID = data_imputed_AREG_test$ID,
  Exited = pred_test
)

write.csv(submission, "submission_........csv", row.names = FALSE)
