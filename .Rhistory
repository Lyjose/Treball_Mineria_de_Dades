step_dummy(all_nominal_predictors(), one_hot = TRUE) %>%
step_center(all_numeric_predictors()) %>%
step_scale(all_numeric_predictors())
library(dplyr)
library(recipes)
# Definir la recepta de preprocessament
recepta <-
recipe(Exited ~ ., data = data) %>%
step_dummy(all_nominal_predictors(), one_hot = TRUE) %>%
step_center(all_numeric_predictors()) %>%
step_scale(all_numeric_predictors())
# Entrenar el model passant-li la recepta directament
model_amb_recipe <- train(
recepta,
data = data,
method = "svmRadial",
tuneGrid = malla,
metric = "F1",
trControl = control_entrenament
)
set.seed(123)
library(smotefamily)
set.seed(123)
library(smotefamily)
set.seed(123)
library(MLmetrics)
library(caret)
library(recipes)
library(dplyr)
data = dataAREG_final[-c(1,2)]
data$Age2 = data$Age^2
data$Age3 = data$Age^3
data$Age3 = data$Age^4
dataAREG_test_final$Age2 = dataAREG_test_final$Age^2
dataAREG_test_final$Age3 = dataAREG_test_final$Age^3
dataAREG_test_final$Age4 = dataAREG_test_final$Age^4
Index <- sample(1:nrow(data), size = nrow(data)*0.8)
dataTrain <- data[Index, ]
dataTest  <- data[-Index, ]
######### PUNTO 2 ###########
# F1
f1 <- function(data, lev = NULL, model = NULL) {
f1_val <- MLmetrics::F1_Score(y_pred = data$pred, y_true = data$obs, positive = "Yes")
c(F1 = f1_val)
}
dataTrain$Exited <- factor(dataTrain$Exited, levels = c(0,1), labels = c("No", "Yes"))
dataTest$Exited  <- factor(dataTest$Exited,  levels = c(0,1), labels = c("No", "Yes"))
control <- trainControl(
method = "repeatedcv",
number = 10,
repeats = 10,
classProbs = TRUE,
summaryFunction = f1,
verboseIter = TRUE
)
set.seed(123)
# Malla de tuning per a C i sigma
malla <- expand.grid(
.C = c(0.5, 1, 2),
.sigma = c(0.01, 0.05, 0.1)
)
library(recipes)
# Definir la recepta de preprocessament
recepta <-
recipe(Exited ~ ., data = data) %>%
step_dummy(all_nominal_predictors(), one_hot = TRUE) %>%
step_center(all_numeric_predictors()) %>%
step_scale(all_numeric_predictors())
# Entrenar el model passant-li la recepta directament
model_amb_recipe <- train(
recepta,
data = data,
method = "svmRadial",
tuneGrid = malla,
metric = "F1",
trControl = control_entrenament
)
# Entrenar el model passant-li la recepta directament
model_amb_recipe <- train(
recepta,
data = data,
method = "svmRadial",
tuneGrid = malla,
metric = "F1",
trControl = control
)
str(dataTrain)
library(kernlab) # Per a SVM
library(pROC)    # Per a la funció de resum prSummary (inclou F1)
# 2. Assegurar la validesa dels noms dels nivells de la variable objectiu
# "No" i "Yes" ja són vàlids, però aquest pas garanteix que la mètrica F1 funcioni
# si hi hagués hagut problemes de noms (com en l'error anterior).
levels(dataTrain$Exited) <- make.names(levels(dataTrain$Exited))
recepta <-
recipe(Exited ~ ., data = dataTrain) %>%
# A. Codificació de Categòriques (Geography, Gender, HasCrCard, IsActiveMember)
# step_dummy converteix tots els factors/nominals a variables 0/1 (One-Hot Encoding)
step_dummy(all_nominal_predictors(), one_hot = FALSE) %>% # one_hot = FALSE: crea k-1 columnes (evita multicolinealitat perfecta)
# B. Normalització de Numèriques (CreditScore, Age, Age2, Age3, etc.)
# S'aplica a totes les variables que quedin i siguin numèriques (originals + dummies)
step_center(all_numeric_predictors()) %>%
step_scale(all_numeric_predictors())
# La funció 'prSummary' proporciona la mètrica F1.
control_entrenament <- trainControl(
method = "repeatedcv",
number = 5,          # 5-fold Cross-Validation
repeats = 3,         # Repetida 3 vegades
summaryFunction = prSummary, # Utilitza la funció que conté F1
classProbs = TRUE,   # Necessari per calcular probabilitats (i F1/AUC)
verboseIter = FALSE
)
# El Kernel Radial (svmRadial) té dos hiperparàmetres principals a optimitzar:
# - C (Cost): Penalització per errors de classificació.
# - sigma: Paràmetre de dispersió del kernel (controla la forma del límit de decisió).
malla_radial <- expand.grid(
.C = c(0.25, 1, 4), # Prova diferents valors de Cost
.sigma = c(0.01, 0.05, 0.1) # Prova diferents valors de sigma
)
# La funció 'prSummary' proporciona la mètrica F1.
control_entrenament <- trainControl(
method = "repeatedcv",
number = 5,          # 5-fold Cross-Validation
repeats = 3,         # Repetida 3 vegades
summaryFunction = f1, # Utilitza la funció que conté F1
classProbs = TRUE,   # Necessari per calcular probabilitats (i F1/AUC)
verboseIter = FALSE
)
# El Kernel Radial (svmRadial) té dos hiperparàmetres principals a optimitzar:
# - C (Cost): Penalització per errors de classificació.
# - sigma: Paràmetre de dispersió del kernel (controla la forma del límit de decisió).
malla_radial <- expand.grid(
.C = c(0.25, 1, 4), # Prova diferents valors de Cost
.sigma = c(0.01, 0.05, 0.1) # Prova diferents valors de sigma
)
model_svm <- train(
recepta,                 # Li passem la recepta de preprocessament
data = dataTrain,        # Les dades originals
method = "svmRadial",    # Kernel de Funció de Base Radial (RBF)
metric = "F1",           # Utilitzem l'F1-score per seleccionar el millor model
tuneGrid = malla_radial, # La malla d'hiperparàmetres
trControl = control_entrenament
)
# 7. Inspeccionar els resultats
print(model_svm)
# Mostrar els resultats detallats de cada combinació C i sigma
model_svm$results
# El millor model es troba a:
model_svm$bestTune
# 1. Extreure la Recepta finalitzada de l'objecte 'train'
# Aquesta recepta ja sap quines columnes centrar/escalar i quins factors codificar.
recepta_finalitzada <- model_svm$preProcess
# 2. Aplicar la transformació a les dades de test
# Utilitzem 'bake()' per aplicar la recepta al nou conjunt de dades.
data_test_processada <- bake(recepta_finalitzada, new_data = dataAREG_test_final)
View(dataAREG_test_final)
# 2. Aplicar la transformació a les dades de test
# Utilitzem 'bake()' per aplicar la recepta al nou conjunt de dades.
data_test_processada <- bake(recepta_finalitzada, new_data = dataAREG_test_final[-2])
View(dataAREG_final)
View(dataAREG_test_final)
View(dataAREG_final)
View(dataTrain)
data = dataAREG_final[-c(1,2)]
data$Age2 = data$Age^2
data$Age3 = data$Age^3
data$Age4 = data$Age^4
dataAREG_test_final$Age2 = dataAREG_test_final$Age^2
dataAREG_test_final$Age3 = dataAREG_test_final$Age^3
dataAREG_test_final$Age4 = dataAREG_test_final$Age^4
Index <- sample(1:nrow(data), size = nrow(data)*0.8)
dataTrain <- data[Index, ]
dataTest  <- data[-Index, ]
######### PUNTO 2 ###########
# F1
f1 <- function(data, lev = NULL, model = NULL) {
f1_val <- MLmetrics::F1_Score(y_pred = data$pred, y_true = data$obs, positive = "Yes")
c(F1 = f1_val)
}
dataTrain$Exited <- factor(dataTrain$Exited, levels = c(0,1), labels = c("No", "Yes"))
dataTest$Exited  <- factor(dataTest$Exited,  levels = c(0,1), labels = c("No", "Yes"))
control <- trainControl(
method = "repeatedcv",
number = 10,
repeats = 10,
classProbs = TRUE,
summaryFunction = f1,
verboseIter = TRUE
)
# 1. Carregar paquets necessaris
library(caret)
library(recipes)
library(kernlab) # Per a SVM
library(pROC)    # Per a la funció de resum prSummary (inclou F1)
# 2. Assegurar la validesa dels noms dels nivells de la variable objectiu
# "No" i "Yes" ja són vàlids, però aquest pas garanteix que la mètrica F1 funcioni
# si hi hagués hagut problemes de noms (com en l'error anterior).
levels(dataTrain$Exited) <- make.names(levels(dataTrain$Exited))
recepta <-
recipe(Exited ~ ., data = dataTrain) %>%
# A. Codificació de Categòriques (Geography, Gender, HasCrCard, IsActiveMember)
# step_dummy converteix tots els factors/nominals a variables 0/1 (One-Hot Encoding)
step_dummy(all_nominal_predictors(), one_hot = FALSE) %>% # one_hot = FALSE: crea k-1 columnes (evita multicolinealitat perfecta)
# B. Normalització de Numèriques (CreditScore, Age, Age2, Age3, etc.)
# S'aplica a totes les variables que quedin i siguin numèriques (originals + dummies)
step_center(all_numeric_predictors()) %>%
step_scale(all_numeric_predictors())
# La funció 'prSummary' proporciona la mètrica F1.
control_entrenament <- trainControl(
method = "repeatedcv",
number = 5,          # 5-fold Cross-Validation
repeats = 3,         # Repetida 3 vegades
summaryFunction = f1, # Utilitza la funció que conté F1
classProbs = TRUE,   # Necessari per calcular probabilitats (i F1/AUC)
verboseIter = FALSE
)
# El Kernel Radial (svmRadial) té dos hiperparàmetres principals a optimitzar:
# - C (Cost): Penalització per errors de classificació.
# - sigma: Paràmetre de dispersió del kernel (controla la forma del límit de decisió).
malla_radial <- expand.grid(
.C = c(0.25, 1, 4), # Prova diferents valors de Cost
.sigma = c(0.01, 0.05, 0.1) # Prova diferents valors de sigma
)
# El Kernel Radial (svmRadial) té dos hiperparàmetres principals a optimitzar:
# - C (Cost): Penalització per errors de classificació.
# - sigma: Paràmetre de dispersió del kernel (controla la forma del límit de decisió).
malla_radial <- expand.grid(
.C = c(0.25), # Prova diferents valors de Cost
.sigma = c(0.01) # Prova diferents valors de sigma
)
model_svm <- train(
recepta,                 # Li passem la recepta de preprocessament
data = dataTrain,        # Les dades originals
method = "svmRadial",    # Kernel de Funció de Base Radial (RBF)
metric = "F1",           # Utilitzem l'F1-score per seleccionar el millor model
tuneGrid = malla_radial, # La malla d'hiperparàmetres
trControl = control_entrenament
)
View(dataAREG_test_final)
str(dataAREG_test_final)
# PARA KAGGLE
# --- 0. Carregar paquets i definir dades de test (per la demostració) ---
library(caret)
library(recipes)
library(kernlab)
library(pROC)
# Recepta: Excloem ID i Surname ja que no són predictores
recepta <-
recipe(Exited ~ ., data = dataTrain) %>%
step_rm(ID, Surname) %>% # <-- EXCLOURE explícitament l'ID i Surname
step_dummy(all_nominal_predictors(), one_hot = FALSE) %>%
step_center(all_numeric_predictors()) %>%
step_scale(all_numeric_predictors())
# Control i Malla (Utilitzant els paràmetres de l'últim exemple)
control_entrenament <- trainControl(
method = "repeatedcv", number = 5, repeats = 3,
summaryFunction = prSummary, classProbs = TRUE
)
malla_radial <- expand.grid(
.C = c(0.25, 1),
.sigma = c(0.01, 0.05)
)
# Pas 3.1: Preparar la recepta amb les dades de test
# Utilitzem 'prep()' per obtenir la recepta finalitzada, ja que la funció 'train()'
# ho fa automàticament i ho desa a model_svm$preProcess
recepta_entrenada <- prep(recepta, training = dataTrain)
# Pas 3.2: Aplicar la transformació al conjunt de test
# Utilitzem bake() amb la recepta ja ajustada amb les dades d'entrenament.
# El nom de les columnes ha de coincidir amb les dummies creades a l'entrenament.
data_test_processada <- bake(recepta_entrenada, new_data = dataAREG_test_final)
malla_radial <- expand.grid(
.C = c(0.25, 1),
.sigma = c(0.01, 0.05)
)
# Pas 3.1: Preparar la recepta amb les dades de test
# Utilitzem 'prep()' per obtenir la recepta finalitzada, ja que la funció 'train()'
# ho fa automàticament i ho desa a model_svm$preProcess
recepta_entrenada <- prep(recepta, training = dataTrain)
# Recepta: Excloem ID i Surname ja que no són predictores
recepta <-
recipe(Exited ~ ., data = dataTrain) %>%
step_rm(Surname) %>% # <-- EXCLOURE explícitament l'ID i Surname
step_dummy(all_nominal_predictors(), one_hot = FALSE) %>%
step_center(all_numeric_predictors()) %>%
step_scale(all_numeric_predictors())
# Control i Malla (Utilitzant els paràmetres de l'últim exemple)
control_entrenament <- trainControl(
method = "repeatedcv", number = 5, repeats = 3,
summaryFunction = prSummary, classProbs = TRUE
)
malla_radial <- expand.grid(
.C = c(0.25, 1),
.sigma = c(0.01, 0.05)
)
# Pas 3.1: Preparar la recepta amb les dades de test
# Utilitzem 'prep()' per obtenir la recepta finalitzada, ja que la funció 'train()'
# ho fa automàticament i ho desa a model_svm$preProcess
recepta_entrenada <- prep(recepta, training = dataTrain)
# Recepta: Excloem ID i Surname ja que no són predictores
recepta <-
recipe(Exited ~ ., data = dataTrain) %>%
step_dummy(all_nominal_predictors(), one_hot = FALSE) %>%
step_center(all_numeric_predictors()) %>%
step_scale(all_numeric_predictors())
# Control i Malla (Utilitzant els paràmetres de l'últim exemple)
control_entrenament <- trainControl(
method = "repeatedcv", number = 5, repeats = 3,
summaryFunction = prSummary, classProbs = TRUE
)
malla_radial <- expand.grid(
.C = c(0.25, 1),
.sigma = c(0.01, 0.05)
)
# Pas 3.1: Preparar la recepta amb les dades de test
# Utilitzem 'prep()' per obtenir la recepta finalitzada, ja que la funció 'train()'
# ho fa automàticament i ho desa a model_svm$preProcess
recepta_entrenada <- prep(recepta, training = dataTrain)
# Pas 3.2: Aplicar la transformació al conjunt de test
# Utilitzem bake() amb la recepta ja ajustada amb les dades d'entrenament.
# El nom de les columnes ha de coincidir amb les dummies creades a l'entrenament.
data_test_processada <- bake(recepta_entrenada, new_data = dataAREG_test_final)
# El model 'model_svm' ja està entrenat per predir amb les columnes transformades.
# Atenció: assegura't que l'objecte 'model_svm' estigui disponible.
pred_test <- predict(model_svm,
newdata = data_test_processada,
type = "raw")
# Pas 3.2: Aplicar la transformació al conjunt de test
# Utilitzem bake() amb la recepta ja ajustada amb les dades d'entrenament.
# El nom de les columnes ha de coincidir amb les dummies creades a l'entrenament.
data_test_processada <- bake(recepta_entrenada, new_data = dataAREG_test_final)
View(data_test_processada)
# El model 'model_svm' ja està entrenat per predir amb les columnes transformades.
# Atenció: assegura't que l'objecte 'model_svm' estigui disponible.
pred_test <- predict(model_svm,
newdata = data_test_processada,
type = "raw")
str(data_test_processada)
# Recepta: Excloem ID i Surname ja que no són predictores
recepta <-
recipe(Exited ~ ., data = dataTrain) %>%
step_dummy(all_nominal_predictors(), one_hot = FALSE) %>%
step_center(all_numeric_predictors()) %>%
step_scale(all_numeric_predictors())
# Control i Malla (Utilitzant els paràmetres de l'últim exemple)
control_entrenament <- trainControl(
method = "repeatedcv", number = 5, repeats = 3,
summaryFunction = prSummary, classProbs = TRUE
)
malla_radial <- expand.grid(
.C = c(0.25, 1),
.sigma = c(0.01, 0.05)
)
# Pas 3.1: Preparar la recepta amb les dades de test
# Utilitzem 'prep()' per obtenir la recepta finalitzada, ja que la funció 'train()'
# ho fa automàticament i ho desa a model_svm$preProcess
recepta_entrenada <- prep(recepta, training = dataTrain)
# Pas 3.2: Aplicar la transformació al conjunt de test
# Utilitzem bake() amb la recepta ja ajustada amb les dades d'entrenament.
# El nom de les columnes ha de coincidir amb les dummies creades a l'entrenament.
data_test_processada <- bake(recepta_entrenada, new_data = dataAREG_test_final)
# El model 'model_svm' ja està entrenat per predir amb les columnes transformades.
# Atenció: assegura't que l'objecte 'model_svm' estigui disponible.
pred_test <- predict(model_svm,
newdata = data_test_processada,
type = "raw")
str(data_test_processada)
# Pas 1.1: Obtenir els noms de les variables (features) que el model_svm va usar durant l'entrenament.
# model_svm$trainingData conté les dades d'entrenament amb el preprocessament aplicat.
# El -1 és per excloure la columna objectiu (Exited).
columnes_predictores <- names(model_svm$trainingData)[-1]
# Pas 1.2: Seleccionar i reordenar les columnes de test EXACTAMENT com les espera el model.
# Utilitzem 'match' per garantir que l'ordre sigui idèntic.
data_test_final_ordenada <- data_test_processada[, columnes_predictores]
# Pas 1.2: Seleccionar i reordenar les columnes de test EXACTAMENT com les espera el model.
# Utilitzem 'match' per garantir que l'ordre sigui idèntic.
data_test_final_ordenada <- data_test_processada[, columnes_predictores]
# --- 2. Predicció Final ---
pred_test <- predict(model_svm,
newdata = data_test_final_ordenada,
type = "raw")
# --- 2. Predicció Final ---
pred_test <- predict(model_svm,
newdata = dataAREG_test_final,
type = "raw")
recepta <-
recipe(Exited ~ ., data = dataAREG_test_final) %>%
# A. Codificació de Categòriques (Geography, Gender, HasCrCard, IsActiveMember)
# step_dummy converteix tots els factors/nominals a variables 0/1 (One-Hot Encoding)
step_dummy(all_nominal_predictors(), one_hot = FALSE) %>% # one_hot = FALSE: crea k-1 columnes (evita multicolinealitat perfecta)
# B. Normalització de Numèriques (CreditScore, Age, Age2, Age3, etc.)
# S'aplica a totes les variables que quedin i siguin numèriques (originals + dummies)
step_center(all_numeric_predictors()) %>%
step_scale(all_numeric_predictors())
# Extreure la recepta finalitzada de l'objecte 'train'
recepta_finalitzada <- model_svm$preProcess
# Aplicar la transformació al nou conjunt de dades.
# La funció 'bake()' s'encarrega d'aplicar el centrat, escalat i les dummies.
data_test_processada <- bake(recepta_finalitzada, new_data = dataAREG_test_final)
# Predir directament sobre les dades transformades.
# Utilitzem 'type = "raw"' per obtenir la classe (No/Yes).
pred_test <- predict(model_svm,
newdata = data_test_processada,
type = "raw")
# Aplicar la transformació al nou conjunt de dades.
# La funció 'bake()' s'encarrega d'aplicar el centrat, escalat i les dummies.
data_test_processada <- bake(recepta_finalitzada, new_data = dataAREG_test_final)
# Si has entrenat amb la sintaxi 'train(recepta, ...)', la recepta finalitzada
# (que conté l'ajust de les mitjanes, desviacions i dummies) es guarda aquí:
recepta_entrenada <- model_svm$recipe
# Ara 'recepta_entrenada' ja no és NULL i conté la informació necessària per 'bake()'.
data_test_processada <- bake(recepta_entrenada, new_data = dataAREG_test_final)
# Si la teva data ja té les columnes correctament processades, la predicció funcionarà.
pred_test <- predict(model_svm,
newdata = data_test_processada,
type = "raw")
# Si la teva data ja té les columnes correctament processades, la predicció funcionarà.
pred_test <- predict(model_svm,
newdata = dataAREG_test_final,
type = "raw")
pred = predict(model_svm,
newdata = dataTest,
type = "raw")
dataTrain <-
# A. Codificació de Categòriques (Geography, Gender, HasCrCard, IsActiveMember)
# step_dummy converteix tots els factors/nominals a variables 0/1 (One-Hot Encoding)
step_dummy(all_nominal_predictors(), one_hot = FALSE) %>% # one_hot = FALSE: crea k-1 columnes (evita multicolinealitat perfecta)
# B. Normalització de Numèriques (CreditScore, Age, Age2, Age3, etc.)
# S'aplica a totes les variables que quedin i siguin numèriques (originals + dummies)
step_center(all_numeric_predictors()) %>%
step_scale(all_numeric_predictors())
dataTrain <-
# A. Codificació de Categòriques (Geography, Gender, HasCrCard, IsActiveMember)
# step_dummy converteix tots els factors/nominals a variables 0/1 (One-Hot Encoding)
mutate(all_nominal_predictors(), one_hot = FALSE) %>% # one_hot = FALSE: crea k-1 columnes (evita multicolinealitat perfecta)
# B. Normalització de Numèriques (CreditScore, Age, Age2, Age3, etc.)
# S'aplica a totes les variables que quedin i siguin numèriques (originals + dummies)
step_center(all_numeric_predictors()) %>%
step_scale(all_numeric_predictors())
# df es tu dataframe original
procesar_datos <- function(df) {
# Creamos receta
rec <- recipe(~ ., data = df) %>%
step_dummy(all_nominal_predictors(), one_hot = TRUE) %>%   # dummies
step_normalize(all_numeric_predictors())                   # escalado
# Entrenamos receta
rec_prep <- prep(rec)
# Aplicamos transformación
df_procesado <- bake(rec_prep, new_data = df)
return(df_procesado)
}
data = procesar_datos(data)
dataAREG_test_final = procesar_datos(dataAREG_test_final)
dataAREG_test_final = procesar_datos(dataAREG_test_final)
load("C:/Users/mdrhu/Treball_Mineria_de_Dades/data_Final_AREG_test.RData")
load("C:/Users/mdrhu/Treball_Mineria_de_Dades/data_Final_AREG_train.RData")
set.seed(123)
library(MLmetrics)
library(caret)
library(recipes)
library(dplyr)
data = dataAREG_final[-c(1,2)]
data$Age2 = data$Age^2
data$Age3 = data$Age^3
data$Age4 = data$Age^4
dataAREG_test_final$Age2 = dataAREG_test_final$Age^2
dataAREG_test_final$Age3 = dataAREG_test_final$Age^3
dataAREG_test_final$Age4 = dataAREG_test_final$Age^4
procesar_datos <- function(df) {
# Creamos receta
rec <- recipe(~ ., data = df) %>%
step_dummy(all_nominal_predictors(), one_hot = TRUE) %>%   # dummies
step_normalize(all_numeric_predictors())                   # escalado
# Entrenamos receta
rec_prep <- prep(rec)
# Aplicamos transformación
df_procesado <- bake(rec_prep, new_data = df)
return(df_procesado)
}
data = procesar_datos(data)
dataAREG_test_final = procesar_datos(dataAREG_test_final)
Index <- sample(1:nrow(data), size = nrow(data)*0.8)
dataTrain <- data[Index, ]
dataTest  <- data[-Index, ]
######### PUNTO 2 ###########
# F1
f1 <- function(data, lev = NULL, model = NULL) {
f1_val <- MLmetrics::F1_Score(y_pred = data$pred, y_true = data$obs, positive = "Yes")
c(F1 = f1_val)
}
dataTrain$Exited <- factor(dataTrain$Exited, levels = c(0,1), labels = c("No", "Yes"))
dataTrain$Exited <- factor(dataTrain$Exited, levels = c(0,1), labels = c("No", "Yes"))
dataTest$Exited  <- factor(dataTest$Exited,  levels = c(0,1), labels = c("No", "Yes"))
View(dataTest)
data = procesar_datos(data, dataAREG_test_final)$train
preprocess_fit <- function(train, test) {
# --- 1. Definir la receta: NO tocar Exited ---
rec <- recipe(Exited ~ ., data = train) %>%
step_dummy(all_nominal_predictors(), one_hot = TRUE) %>%
step_normalize(all_numeric_predictors())
# --- 2. Entrenar receta SOLO con train ---
rec_prep <- prep(rec, training = train)
# --- 3. Transformar train ---
train_processed <- bake(rec_prep, new_data = train)
# --- 4. Transformar test (sin Exited) ---
test_processed  <- bake(rec_prep, new_data = test)
return(list(
recipe = rec_prep,
train = train_processed,
test = test_processed
))
}
data = procesar_datos(data, dataAREG_test_final)$train
dataAREG_test_final =procesar_datos(data, dataAREG_test_final)$test
