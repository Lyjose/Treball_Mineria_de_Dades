family = binomial(link = "logit"),
data = dataTrain
)
AIC(mod1);AIC(mod_splines);AIC(mod_splines2)
plot(mod_splines2)
summary(mod_splines2)
prob3 = predict(mod_splines2, newdata = dataTest, type="response")
pred3= ifelse( prob3 > 0.3,"Yes","No")
MLmetrics::F1_Score(dataTest$Exited,pred3)
MLmetrics::Specificity(dataTest$Exited,pred3)
ConfusionMatrix(pred3,dataTest$Exited)
pred3= ifelse( prob3 > 0.4,"Yes","No")
MLmetrics::F1_Score(dataTest$Exited,pred3)
MLmetrics::Specificity(dataTest$Exited,pred3)
ConfusionMatrix(pred3,dataTest$Exited)
pred3= ifelse( prob3 > 0.1,"Yes","No")
MLmetrics::F1_Score(dataTest$Exited,pred3)
MLmetrics::Specificity(dataTest$Exited,pred3)
ConfusionMatrix(pred3,dataTest$Exited)
######################### ELASTIC NET #########################################
cl <- makeCluster(detectCores() - 1)
registerDoParallel(cl)
# Fórmula con splines
formula_completa <- Exited ~
ns(Age, df = 4) +
ns(CreditScore, df = 2) +
ns(Balance, df = 2) +
ns(Tenure, df = 1) +
ns(NetPromoterScore, df = 3) +
ns(TransactionFrequency, df = 1) +
ns(AvgTransactionAmount, df = 1) +
ns(DigitalEngagementScore, df = 1) +
EstimatedSalary +
Gender + EducationLevel + LoanStatus + Geography +
ComplaintsCount + HasCrCard + IsActiveMember +
CustomerSegment + MaritalStatus + SavingsAccountFlag +
NumOfProducts
# TODAS las interacciones de orden 2
formula_interacciones <- update(formula_completa, ~ (.)^2)
# Configuración CV optimizando F1
train_control_f1 <- trainControl(
method = "cv",
number = 5,
classProbs = TRUE,
summaryFunction = f1,     # FUNCIÓN PERSONALIZADA F1
verboseIter = TRUE,
allowParallel = TRUE,
preProcOptions = list(verbose = TRUE)  # Intenta esto
)
# Configuración CV optimizando F1
train_control_f1 <- trainControl(
method = "cv",
number = 5,
classProbs = TRUE,
summaryFunction = f1,
verboseIter = TRUE,
allowParallel = TRUE
)
# Grid de hiperparámetros
elastic_grid <- expand.grid(
alpha = seq(0, 1, by = 0.2),
lambda = exp(seq(-4, 0, length.out = 10))
)
elastic_f1 <- train(
formula_interacciones,
data = dataTrain,
method = "glmnet",
trControl = train_control_f1,
tuneGrid = elastic_grid,
metric = "F1",                    # OPTIMIZAR F1
family = "binomial"
)
prob3 = predict(elastic_f1, newdata = dataTest, type="prob")
pred3 = ifelse( prob3 > 0.25,"Yes","No")[,2]
MLmetrics::F1_Score(dataTest$Exited,pred3)
MLmetrics::Specificity(dataTest$Exited,pred3)
load("C:/Users/mdrhu/Treball_Mineria_de_Dades/0_Bases_de_dades/Imputed/data_NA_imputed_MICE_test.RData")
prob3 = predict(elastic_f1, newdata = dataTest, type="prob")
View(prob3)
pred3 = ifelse( prob3 > 0.25,"Yes","No")[,1]
MLmetrics::F1_Score(dataTest$Exited,pred3)
MLmetrics::Specificity(dataTest$Exited,pred3)
pred3 = ifelse( prob3 > 0.25,"Yes","No")[,2]
MLmetrics::F1_Score(dataTest$Exited,pred3)
MLmetrics::Specificity(dataTest$Exited,pred3)
thresholds <- seq(0.01, 0.8, by = 0.01)
# Inicializar un vector para almacenar los resultados del F1
f1_scores <- numeric(length(thresholds))
# Loop para probar cada threshold y calcular el F1
for (i in seq_along(thresholds)) {
threshold <- thresholds[i]
preds <- ifelse(prob3 > threshold, "Yes", "No")
f1_scores[i] <- MLmetrics::F1_Score(y_pred = preds, y_true = dataTest$Exited, positive = "Yes")
}
# Loop para probar cada threshold y calcular el F1
for (i in seq_along(thresholds)) {
threshold <- thresholds[i]
preds <- ifelse(prob3 > threshold, "Yes", "No")
f1_scores[i] <- MLmetrics::F1_Score(y_pred = preds[,2], y_true = dataTest$Exited, positive = "Yes")
}
threshold_f1_df <- data.frame(Threshold = thresholds, F1_Score = f1_scores)
print(threshold_f1_df)
best_threshold <- threshold_f1_df$Threshold[which.max(threshold_f1_df$F1_Score)]
best_threshold
preds_testtrain <- ifelse(probs > best_threshold, "Yes", "No")
threshold_f1_df <- data.frame(Threshold = thresholds, F1_Score = f1_scores)
print(threshold_f1_df)
best_threshold <- threshold_f1_df$Threshold[which.max(threshold_f1_df$F1_Score)]
best_threshold
preds_testtrain <- ifelse(probs > best_threshold, "Yes", "No")
preds_testtrain <- ifelse(prob3 > best_threshold, "Yes", "No")
# CM
cm_best <- confusionMatrix(
factor(preds_testtrain, levels = c("No", "Yes")),
dataTest$Exited,
positive = "Yes"
); print(cm_best)
MLmetrics::F1_Score(dataTest$Exited,preds_testtrain,"Yes")
preds_testtrain <- ifelse(prob3 > best_threshold, "Yes", "No")[,2]
# CM
cm_best <- confusionMatrix(
factor(preds_testtrain, levels = c("No", "Yes")),
dataTest$Exited,
positive = "Yes"
); print(cm_best)
MLmetrics::F1_Score(dataTest$Exited,preds_testtrain,"Yes")
View(data_imputed_MICE)
summary(dataTrain)
View(data_imputed_MICE)
load("C:/Users/mdrhu/Treball_Mineria_de_Dades/0_Bases_de_dades/Imputed/data_NA_imputed_MICE.RData")
# ============================================================
# 2) Preparar dataset
# ============================================================
df <- data_imputed_MICE[,-c(7,18)]
# ============================================================
# 2) Preparar dataset
# ============================================================
data <- data_imputed_MICE[,-c(7,18)]
set.seed(123)
Index <- sample(1:nrow(data), size = nrow(data)*0.8)
dataTrain <- data[Index, ]
dataTest  <- data[-Index, ]
# Convertir target a 0/1 numérico
df$Exited <- ifelse(df$Exited == "Yes", 1, 0)
data$Exited <- ifelse(df$Exited == "Yes", 1, 0)
set.seed(123)
Index <- sample(1:nrow(data), size = nrow(data)*0.8)
dataTrain <- data[Index, ]
dataTest  <- data[-Index, ]
# Categóricas
cat_features <- which(sapply(df, is.factor))
# ============================================================
# 3) Definir función auxiliar para evaluar F1 con threshold
# ============================================================
f1_threshold <- function(probs, truth, threshold) {
pred <- ifelse(probs > threshold, 1, 0)
return(F1_Score(y_pred = pred, y_true = truth))
}
# Grid compacto pero efectivo (puedes ampliarlo si quieres)
grid <- expand.grid(
depth          = c(4, 6, 8),
learning_rate  = c(0.01, 0.03, 0.1),
l2_leaf_reg    = c(1, 3, 5),
bagging_temperature = c(0.5, 1)
)
best_f1 <- -Inf
best_params <- NULL
for(i in 1:nrow(grid)){
params_try <- list(
loss_function = "Logloss",
iterations = 1500,
depth = grid$depth[i],
learning_rate = grid$learning_rate[i],
l2_leaf_reg = grid$l2_leaf_reg[i],
bagging_temperature = grid$bagging_temperature[i],
eval_metric = "F1",
random_seed = 123,
logging_level = "Silent"
)
# Create pool
pool <- catboost.load_pool(
data = df[, setdiff(names(df), "Exited")],
label = df$Exited,
cat_features = cat_features
)
# Cross Validation
cv <- catboost.cv(
pool,
params = params_try,
fold_count = 5,
type = "Classical",
partition_random_seed = 123,
verbose = FALSE
)
mean_f1 <- max(cv$test.F1.mean)
cat(">>> Probando params ", i, "/", nrow(grid),
" — F1 =", mean_f1, "\n")
if(mean_f1 > best_f1){
best_f1 <- mean_f1
best_params <- params_try
}
}
df = dataTrain
for(i in 1:nrow(grid)){
params_try <- list(
loss_function = "Logloss",
iterations = 1500,
depth = grid$depth[i],
learning_rate = grid$learning_rate[i],
l2_leaf_reg = grid$l2_leaf_reg[i],
bagging_temperature = grid$bagging_temperature[i],
eval_metric = "F1",
random_seed = 123,
logging_level = "Silent"
)
# Create pool
pool <- catboost.load_pool(
data = df[, setdiff(names(df), "Exited")],
label = df$Exited,
cat_features = cat_features
)
# Cross Validation
cv <- catboost.cv(
pool,
params = params_try,
fold_count = 5,
type = "Classical",
partition_random_seed = 123,
verbose = FALSE
)
mean_f1 <- max(cv$test.F1.mean)
cat(">>> Probando params ", i, "/", nrow(grid),
" — F1 =", mean_f1, "\n")
if(mean_f1 > best_f1){
best_f1 <- mean_f1
best_params <- params_try
}
}
library(catboost)
library(MLmetrics)
library(pROC)
for(i in 1:nrow(grid)){
params_try <- list(
loss_function = "Logloss",
iterations = 1500,
depth = grid$depth[i],
learning_rate = grid$learning_rate[i],
l2_leaf_reg = grid$l2_leaf_reg[i],
bagging_temperature = grid$bagging_temperature[i],
eval_metric = "F1",
random_seed = 123,
logging_level = "Silent"
)
# Create pool
pool <- catboost.load_pool(
data = df[, setdiff(names(df), "Exited")],
label = df$Exited,
cat_features = cat_features
)
# Cross Validation
cv <- catboost.cv(
pool,
params = params_try,
fold_count = 5,
type = "Classical",
partition_random_seed = 123,
verbose = FALSE
)
mean_f1 <- max(cv$test.F1.mean)
cat(">>> Probando params ", i, "/", nrow(grid),
" — F1 =", mean_f1, "\n")
if(mean_f1 > best_f1){
best_f1 <- mean_f1
best_params <- params_try
}
}
for(i in 1:nrow(grid)){
params_try <- list(
loss_function = "Logloss",
iterations = 1500,
depth = grid$depth[i],
learning_rate = grid$learning_rate[i],
l2_leaf_reg = grid$l2_leaf_reg[i],
bagging_temperature = grid$bagging_temperature[i],
eval_metric = "F1",
random_seed = 123,
logging_level = "Silent"
)
# Create pool
pool <- catboost.load_pool(
data = df[, setdiff(names(df), "Exited")],
label = df$Exited,
)
# Cross Validation
cv <- catboost.cv(
pool,
params = params_try,
fold_count = 5,
type = "Classical",
partition_random_seed = 123,
)
mean_f1 <- max(cv$test.F1.mean)
cat(">>> Probando params ", i, "/", nrow(grid),
" — F1 =", mean_f1, "\n")
if(mean_f1 > best_f1){
best_f1 <- mean_f1
best_params <- params_try
}
}
data$Exited <- as.numeric(ifelse(df$Exited == "Yes", 1, 0))
# ============================================================
# 2) Preparar dataset
# ============================================================
data <- data_imputed_MICE[,-c(7,18)]
data$Exited <- as.numeric(ifelse(df$Exited == "Yes", 1, 0))
data$Exited <- as.numeric(ifelse(data$Exited == "Yes", 1, 0))
# ============================================================
# 2) Preparar dataset
# ============================================================
data <- data_imputed_MICE[,-c(7,18)]
data$Exited <- as.numeric(ifelse(data$Exited == "Yes", 1, 0))
set.seed(123)
Index <- sample(1:nrow(data), size = nrow(data)*0.8)
dataTrain <- data[Index, ]
dataTest  <- data[-Index, ]
df = dataTrain
# Categóricas
cat_features <- which(sapply(df, is.factor))
# ============================================================
# 3) Definir función auxiliar para evaluar F1 con threshold
# ============================================================
f1_threshold <- function(probs, truth, threshold) {
pred <- ifelse(probs > threshold, 1, 0)
return(F1_Score(y_pred = pred, y_true = truth))
}
# Grid compacto pero efectivo (puedes ampliarlo si quieres)
grid <- expand.grid(
depth          = c(4, 6, 8),
learning_rate  = c(0.01, 0.03, 0.1),
l2_leaf_reg    = c(1, 3, 5),
bagging_temperature = c(0.5, 1)
)
best_f1 <- -Inf
best_params <- NULL
for(i in 1:nrow(grid)){
params_try <- list(
loss_function = "Logloss",
iterations = 1500,
depth = grid$depth[i],
learning_rate = grid$learning_rate[i],
l2_leaf_reg = grid$l2_leaf_reg[i],
bagging_temperature = grid$bagging_temperature[i],
eval_metric = "F1",
random_seed = 123,
logging_level = "Silent"
)
# Create pool
pool <- catboost.load_pool(
data = df[, setdiff(names(df), "Exited")],
label = df$Exited,
)
# Cross Validation
cv <- catboost.cv(
pool,
params = params_try,
fold_count = 5,
type = "Classical",
partition_random_seed = 123,
)
mean_f1 <- max(cv$test.F1.mean)
cat(">>> Probando params ", i, "/", nrow(grid),
" — F1 =", mean_f1, "\n")
if(mean_f1 > best_f1){
best_f1 <- mean_f1
best_params <- params_try
}
}
data <- data_imputed_MICE[,-c(7,18)]
Index <- sample(1:nrow(data), size = nrow(data)*0.8)
dataTrain <- data[Index, ]
dataTest  <- data[-Index, ]
# Convertir caracteres a factores
dataTrain <- dataTrain %>% mutate(across(where(is.character), as.factor))
dataTest  <- dataTest %>% mutate(across(where(is.character), as.factor))
# Alinear niveles entre train y test
for(col in names(dataTrain)) {
if(is.factor(dataTrain[[col]])) {
dataTest[[col]] <- factor(dataTest[[col]], levels = levels(dataTrain[[col]]))
}
}
# Variable objetivo numérica
dataTrain$Exited_num <- ifelse(dataTrain$Exited == "Yes" | dataTrain$Exited == "1", 1, 0)
dataTest$Exited_num  <- ifelse(dataTest$Exited == "Yes" | dataTest$Exited == "1", 1, 0)
# Crear pool completo
train_pool <- catboost.load_pool(
data = dataTrain %>% select(-Exited, -Exited_num),
label = dataTrain$Exited_num
)
test_pool <- catboost.load_pool(
data = dataTest %>% select(-Exited, -Exited_num),
label = dataTest$Exited_num
)
grid <- expand.grid(
depth = c(4,6,8),
learning_rate = c(0.03,0.05,0.1),
l2_leaf_reg = c(1,3,5)
)
library(purrr)
results <- purrr::pmap_dfr(
list(
depth = as.numeric(grid$depth),
learning_rate = as.numeric(grid$learning_rate),
l2_leaf_reg = as.numeric(grid$l2_leaf_reg)
),
function(depth, learning_rate, l2_leaf_reg){
params <- list(
loss_function = "Logloss",
eval_metric = "F1",
iterations = 250,
depth = depth,
learning_rate = learning_rate,
l2_leaf_reg = l2_leaf_reg,
random_seed = 42,
border_count = 254
)
cv <- catboost.cv(
pool = train_pool,
params = params,
fold_count = 5,
type = "Classical",
stratified = TRUE,
partition_random_seed = 42,
early_stopping_rounds = 30
)
data.frame(
depth = depth,
learning_rate = learning_rate,
l2_leaf_reg = l2_leaf_reg,
F1_mean = max(cv$test.F1.mean)
)
}
)
# Mejor hiperparámetro
best_params <- results[which.max(results$F1_mean), ]
print(best_params)
final_params <- list(
loss_function = "Logloss",
eval_metric = "F1",
iterations = 1500,  # más iteraciones para modelo final
depth = best_params$depth,
learning_rate = best_params$learning_rate,
l2_leaf_reg = best_params$l2_leaf_reg,
random_seed = 123,
border_count = 254,
early_stopping_rounds = 50
)
modelo_catboost <- catboost.train(
learn_pool = train_pool,
test_pool = NULL,
params = final_params
)
pred_prob <- catboost.predict(
modelo_catboost,
test_pool,
prediction_type = "Probability"
)
thresholds <- seq(0.01, 0.99, by = 0.01)
f1_scores <- sapply(thresholds, function(th){
preds <- ifelse(pred_prob > th, 1, 0)
MLmetrics::F1_Score(y_pred = preds, y_true = dataTest$Exited_num, positive = 1)
})
best_threshold <- thresholds[which.max(f1_scores)]
cat("Mejor threshold F1:", best_threshold, "\n")
best_threshold2 <- thresholds[which.max(recall)]
cat("Mejor threshold Recall:", best_threshold2, "\n")
# Predicciones finales con threshold óptimo
preds_test <- ifelse(pred_prob > best_threshold, 1, 0)
cm_best <- caret::confusionMatrix(
factor(preds_test, levels = c(0,1)),
factor(dataTest$Exited_num, levels = c(0,1)),
positive = "0"
)
print(cm_best)
MLmetrics::F1_Score(preds_test,dataTest$Exited_num)
load("C:/Users/mdrhu/Treball_Mineria_de_Dades/0_Bases_de_dades/Imputed/data_NA_imputed_MICE_test.RData")
# 1. Obtener probabilidades de test
Test = data_imputed_MICE_test[-6]
test_pool_kaggle <- catboost.load_pool(
data = Test
)
probs_test <- catboost.predict(
modelo_catboost,
test_pool_kaggle,
prediction_type = "Probability"
)
# 2. Aplicar el mejor threshold encontrado
pred_test <- ifelse(probs_test > best_threshold, "Yes", "No")
# 3. Crear el dataframe de submission
submission <- data.frame(
ID = data_imputed_AREG_test$ID,
Exited = pred_test
)
# 3. Crear el dataframe de submission
submission <- data.frame(
ID = data_imputed_MICE_test$ID,
Exited = pred_test
)
# 4. Guardar el CSV
write.csv(submission, "submission_catboost2.csv", row.names = FALSE)
MLmetrics::F1_Score(preds_test,dataTest$Exited_num)
getwd()
View(submission)
